{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spoken commands example\n",
    "This example uses an audio classifier model from a Tensorflow tutorial:\n",
    "https://www.tensorflow.org/tutorials/sequences/audio_recognition\n",
    "\n",
    "**N.B. This script downloads a large (2.3GB) speech commands dataset!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.wavfile import read, write\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from src.problemgenerator.series import Series\n",
    "from src.problemgenerator.tuple import Tuple\n",
    "from src.problemgenerator.filters import ClipWAV, ApplyToTuple\n",
    "from src.plotting.utils import visualize_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we download the dataset unless it is already present.\n",
    "# If you have downloaded and extracted the dataset into a different directory,\n",
    "# change the data_dir variable accordingly.\n",
    "\n",
    "data_url = \"https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz\"\n",
    "fname = \"speech_commands_v0.02.tar.gz\"\n",
    "data_dir = Path.home() / \"datasets/speech_data\"\n",
    "\n",
    "if not data_dir.exists():\n",
    "    !mkdir -p {data_dir}\n",
    "    !wget {data_url} -P {data_dir}\n",
    "    tarfile.open(data_dir / fname, \"r:gz\").extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_categories = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]\n",
    "labels = [\"_silence_\", \"_unknown_\", \"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]\n",
    "\n",
    "test_set_rel_paths = !cat {data_dir / \"testing_list.txt\"}\n",
    "test_set_files = [data_dir / p for p in test_set_rel_paths]\n",
    "test_categories = !cut -d'/' -f1 {data_dir / \"testing_list.txt\"} | sort -u\n",
    "\n",
    "len(test_set_files), len(test_categories), len(trained_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your dpEmu folder is not located directly under your home directory,\n",
    "# change the example_path variable accordingly.\n",
    "\n",
    "example_path = Path.home() / \"dpEmu/src/examples/speech_commands\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a category in which to generate errors.\n",
    "# Later on we will generate errors in all of the test set categories.\n",
    "\n",
    "category = \"stop\"\n",
    "data_subset_dir = data_dir / category\n",
    "\n",
    "fs = list(data_subset_dir.iterdir())\n",
    "wavs = [read(f) for f in data_subset_dir.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an error generating tree and generate errors\n",
    "# in the category chosen above.\n",
    "\n",
    "wav_node = Tuple()\n",
    "wav_node.addfilter(ApplyToTuple(ClipWAV(\"dyn_range\"), 1))\n",
    "root_node = Series(wav_node)\n",
    "\n",
    "err_params = {\"dyn_range\": .2}\n",
    "clipped = root_node.generate_error(wavs, err_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_index = 123  # Arbitrarily chosen speech command example â€“ try changing the index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_filename = data_dir / 'clipped.wav'\n",
    "write(clipped_filename, 16000, clipped[example_index][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aplay {fs[example_index]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aplay {clipped_filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to filter out irrelevant output (e.g. Python deprecation warnings)\n",
    "\n",
    "def filter_scores(output):\n",
    "    return [line for line in output if \"score\" in line or \".wav\" in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the model on the clean clip selected above.\n",
    "\n",
    "scores_clean = !python {example_path}/label_wav.py \\\n",
    "--graph={example_path}/trained_model/my_frozen_graph.pb \\\n",
    "--labels={example_path}/trained_model/conv_labels.txt \\\n",
    "--wav={fs[example_index]}\n",
    "\n",
    "filter_scores(scores_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model on the corresponding errorified clip.\n",
    "\n",
    "scores_clipped = !python {example_path}/label_wav.py \\\n",
    "--graph={example_path}/trained_model/my_frozen_graph.pb \\\n",
    "--labels={example_path}/trained_model/conv_labels.txt \\\n",
    "--wav={clipped_filename}\n",
    "\n",
    "filter_scores(scores_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also run the model on an entire directory of .wav files in one go\n",
    "\n",
    "scores_clean_dir = !python {example_path}/label_wav_dir.py \\\n",
    "--graph={example_path}/trained_model/my_frozen_graph.pb \\\n",
    "--labels={example_path}/trained_model/conv_labels.txt \\\n",
    "--wav_dir={data_subset_dir}\n",
    "\n",
    "filter_scores(scores_clean_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That was not pretty! We'd better define some helper functions to extract\n",
    "# the model's guesses from that messy output.\n",
    "\n",
    "def get_guesses(scores):\n",
    "    scores = filter_scores(scores)\n",
    "    if len(scores) % 4 != 0:\n",
    "        raise ValueError(f\"Expected scores list to have a length divisible by 4 after filtering but got length {len(scores)}\")\n",
    "    num_files = len(scores) / 4\n",
    "    fnames = scores[0::4]\n",
    "    guesses = [guess.split(' ')[0] for guess in scores[1::4]]\n",
    "    return zip(fnames, guesses)\n",
    "\n",
    "def score_directory(directory):\n",
    "    scores = !python {example_path}/label_wav_dir.py \\\n",
    "        --graph={example_path}/trained_model/my_frozen_graph.pb \\\n",
    "        --labels={example_path}/trained_model/conv_labels.txt \\\n",
    "        --wav_dir={directory}\n",
    "    return filter_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate errors in all wav files in a given directory.\n",
    "# If an inclusion list is provided, only files on the list will be processed.\n",
    "\n",
    "def errorify_directory(data_root_dir, dir_name, tree_root, err_params, inclusion_list=None):\n",
    "    clean_data_dir = data_root_dir / dir_name\n",
    "    if not clean_data_dir.exists():\n",
    "        raise ValueError(f\"Directory {clean_data_dir} does not exist.\")\n",
    "    err_data_dir = data_root_dir / (dir_name + \"_err\")\n",
    "    if not err_data_dir.exists():\n",
    "        !mkdir {err_data_dir}\n",
    "    if not inclusion_list:\n",
    "        inclusion_list = [f for f in clean_data_dir.iterdir() if \".wav\" in str(f)]\n",
    "    for file in inclusion_list:\n",
    "        fname = file.name\n",
    "        wav = read(file)\n",
    "        clipped = tree_root.generate_error([wav], err_params)[0]\n",
    "        err_file_path = err_data_dir / fname\n",
    "        write(err_file_path, clipped[0], clipped[1])\n",
    "    return err_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate errors in all wav files on a list.\n",
    "# The function is needed when files from multiple categories are present on the list.\n",
    "# To facilitate comparisons between clean and errorified data, the clean files\n",
    "# the list can be automatically copied to suitably named directories. To do this,\n",
    "# provide the parameter copy_clean=True.\n",
    "\n",
    "def errorify_list(data_files, categories, tree_root, err_params, copy_clean=False):\n",
    "    data_root_dir = data_files[0].parents[1]\n",
    "    print(f\"data root dir: {data_root_dir}\")\n",
    "    for cat in categories:\n",
    "        files_in_cat = [f for f in data_files if (cat + \"/\") in str(f)]\n",
    "        print(\"category:\", cat)\n",
    "        print(f\"{len(files_in_cat)}\")\n",
    "        errorify_directory(data_root_dir, cat, tree_root, err_params, inclusion_list=files_in_cat)\n",
    "        if copy_clean:\n",
    "            copy_dir = data_root_dir / (cat + \"_clean\")\n",
    "            !mkdir {copy_dir}\n",
    "            for file in files_in_cat:\n",
    "                shutil.copy(file, copy_dir)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compare the model's guesses on clean and errorified data.\n",
    "# The results are returned in a Pandas dataframe.\n",
    "\n",
    "def compare(data_root, category, clean_ext=\"_clean\", err_ext=\"_err\"):\n",
    "    scores_clean = score_directory(data_root / (category + clean_ext))\n",
    "    guesses_clean = get_guesses(scores_clean)\n",
    "    scores_err = score_directory(data_root / (category + err_ext))\n",
    "    guesses_err = get_guesses(scores_err)\n",
    "    df_clean = pd.DataFrame(guesses_clean, columns=[\"file\", \"clean_guess\"])\n",
    "    df_err = pd.DataFrame(guesses_err, columns=[\"file\", \"err_guess\"])\n",
    "    res = pd.merge(df_clean, df_err, on=\"file\", how=\"inner\")\n",
    "    res['true_label'] = category\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate errors in all test set audio clips.\n",
    "\n",
    "errorify_list(test_set_files, trained_categories, root_node, err_params, copy_clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model on clean and errorified data.\n",
    "\n",
    "results = [compare(data_dir, cat) for cat in trained_categories]\n",
    "df = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrices for clean and errorified date, respectively.\n",
    "\n",
    "cm_clean = confusion_matrix(df['true_label'], df['clean_guess'], labels=labels)\n",
    "cm_err = confusion_matrix(df['true_label'], df['err_guess'], labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize the confusion matrix for clean data.\n",
    "\n",
    "visualize_confusion_matrix(df, cm_clean, 0, labels, \"dyn_range\", \"true_label\", \"clean_guess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the confusion matrix for errorified data.\n",
    "\n",
    "visualize_confusion_matrix(df, cm_err, 0, labels, \"dyn_range\", \"true_label\", \"err_guess\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
