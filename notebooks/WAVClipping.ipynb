{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spoken commands example\n",
    "This example uses an audio classifier model from a Tensorflow tutorial:\n",
    "https://www.tensorflow.org/tutorials/sequences/audio_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read, write\n",
    "from src.problemgenerator.series import Series\n",
    "from src.problemgenerator.tuple import Tuple\n",
    "from src.problemgenerator.filters import ClipWAV, ApplyToTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz\"\n",
    "fname = \"speech_commands_v0.02.tar.gz\"\n",
    "data_dir = Path.home() / \"datasets/speech_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_dir.exists():\n",
    "    !mkdir -p {data_dir}\n",
    "    !wget {data_url} -P {data_dir}\n",
    "    tarfile.open(data_dir / fname, \"r:gz\").extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_path = Path.home() / \"dpEmu/src/examples/speech_commands\"\n",
    "data_subset_dir = data_dir / \"off\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = list(data_subset_dir.iterdir())\n",
    "wavs = [read(f) for f in data_subset_dir.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_node = Tuple()\n",
    "wav_node.addfilter(ApplyToTuple(ClipWAV(\"dyn_range\"), 1))\n",
    "root_node = Series(wav_node)\n",
    "clipped = root_node.generate_error(wavs, {\"dyn_range\": .3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_index = 22  # Arbitrarily chosen speech command example â€“ try changing the index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write('clipped.wav', 16000, clipped[example_index][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aplay {fs[example_index]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aplay clipped.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_clean = !python {example_path}/label_wav.py \\\n",
    "--graph={example_path}/trained_model/my_frozen_graph.pb \\\n",
    "--labels={example_path}/trained_model/conv_labels.txt \\\n",
    "--wav={fs[example_index]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_clipped = !python {example_path}/label_wav.py \\\n",
    "--graph={example_path}/trained_model/my_frozen_graph.pb \\\n",
    "--labels={example_path}/trained_model/conv_labels.txt \\\n",
    "--wav='clipped.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to filter out irrelevant output (e.g. Python deprecation warnings)\n",
    "def filter_scores(output):\n",
    "    return [line for line in output if \"score\" in line or \".wav\" in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_scores(scores_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_scores(scores_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also obtain the scores for an entire directory of .wav files in one command\n",
    "scores_clean_dir = !python {example_path}/label_wav_dir.py \\\n",
    "--graph={example_path}/trained_model/my_frozen_graph.pb \\\n",
    "--labels={example_path}/trained_model/conv_labels.txt \\\n",
    "--wav_dir={data_subset_dir}\n",
    "\n",
    "filter_scores(scores_clean_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
